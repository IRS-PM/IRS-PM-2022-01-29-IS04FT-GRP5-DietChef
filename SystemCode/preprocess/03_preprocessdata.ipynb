{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install ipynb # used to import another ipynb\n",
    "# !pip install python-dotenv # used to load .env file\n",
    "\n",
    "# Load env should run it very first\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper.csvhelper' from '/Users/roychiu/Desktop/ISS Master/GroupProject1/preprocess/helper/csvhelper.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# from preprocess.readcsv import read\n",
    "# from preprocess import esClient\n",
    "import helper.eshelper as eshelper\n",
    "import helper.csvhelper as csvhelper\n",
    "\n",
    "import importlib\n",
    "importlib.reload(eshelper)\n",
    "importlib.reload(csvhelper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read recipe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\n",
    "    \"query\",\n",
    "    \"recipe_id\",\n",
    "    \"publisher\",\n",
    "    'source_url', \n",
    "    'image_url', \n",
    "    'social_rank', \n",
    "    'publisher_url', \n",
    "    'title', \n",
    "    'sum_cal', \n",
    "    'sum_fat', \n",
    "    'sum_carb', \n",
    "    'sum_protein'\n",
    "]\n",
    "recipeData = csvhelper.read(\"../data/recipe.csv\", header)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### push recipe data to es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushing 3166 documents\n",
      "(3166, [])\n",
      "pushed to elasticsearch\n"
     ]
    }
   ],
   "source": [
    "#push recipe to elasticsearch\n",
    "err = eshelper.bulkIndex(recipeData,\"recipe_raw\",\"{recipe_id}\")\n",
    "if err != None:\n",
    "    print(err)\n",
    "else:\n",
    "    print(\"pushed to elasticsearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read ingredient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ingredient data\n",
    "header = [\n",
    "    \"query\",\n",
    "    \"recipe_id\",\n",
    "    \"quantity\",\n",
    "    \"unit\",\n",
    "    \"weight_g\",\n",
    "    \"raw_ingredient\",\n",
    "    \"ingredient\",\n",
    "    \"nutrition_value\"\n",
    "    \"cal\",\n",
    "    'fat', \n",
    "    'cah', \n",
    "    'protein', \n",
    "    'original_ingredient'\n",
    "]\n",
    "ingredientData = csvhelper.read(\"../data/ingredient.csv\", header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### push ingredient data to es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushing 35827 documents\n",
      "181 document(s) failed to index.\n"
     ]
    }
   ],
   "source": [
    "#push recipe to elasticsearch\n",
    "err = eshelper.bulkIndex(ingredientData,\"recipe_ingredient_raw\",\"{recipe_id}-{ingredient}\")\n",
    "if err != None:\n",
    "    print(err)\n",
    "else:\n",
    "    print(\"pushed to elasticsearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get similarity result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### result is in id -> [recipes] format\n",
    "with open('../data/similarity_result.json', 'r') as f:\n",
    "    SIMILAR_RECIPES = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary by recipe id\n",
    "recipeDict = {}\n",
    "for recipe in recipeData:\n",
    "    recipe_id = recipe[\"recipe_id\"]\n",
    "    recipeDict[recipe_id] = recipe.copy()\n",
    "    recipeDict[recipe_id][\"ingredients\"] = []\n",
    "    recipeDict[recipe_id][\"ingredients_g\"] = {}\n",
    "    recipeDict[recipe_id][\"ingredients_weight_g\"] = []\n",
    "    recipeDict[recipe_id][\"ingredients_g_normalised\"] = []\n",
    "    recipeDict[recipe_id][\"ingredients_popularity\"] = {}\n",
    "    recipeDict[recipe_id][\"ingredients_name\"] = \"\"\n",
    "    recipeDict[recipe_id][\"total_ingredient_weight_g\"] = 0\n",
    "    recipeDict[recipe_id][\"min_ingredient_weight_g\"] = float(\"inf\")\n",
    "    # similar recipes\n",
    "    if recipe_id in SIMILAR_RECIPES:\n",
    "        recipeDict[recipe_id][\"similar_recipes\"] = [ {\"recipe_id\": v['recipe_id'],\"score\": v['score'] } for v in SIMILAR_RECIPES[recipe_id]]\n",
    "\n",
    "# push ingredient to recipe\n",
    "for ingredient in ingredientData:\n",
    "    recipe_id = ingredient[\"recipe_id\"]\n",
    "    recipeDict[recipe_id][\"ingredients\"].append(ingredient)\n",
    "    recipeDict[recipe_id][\"ingredients_name\"] += \" {0}\".format(ingredient['ingredient'])\n",
    "    recipeDict[recipe_id][\"total_ingredient_weight_g\"] += ingredient[\"weight_g\"]\n",
    "    recipeDict[recipe_id][\"ingredients_g\"][ingredient[\"ingredient\"].strip()] = int(ingredient[\"weight_g\"])\n",
    "    if ingredient[\"weight_g\"] < recipeDict[recipe_id][\"min_ingredient_weight_g\"]:\n",
    "        # get the min weight and normalise it later\n",
    "        recipeDict[recipe_id][\"min_ingredient_weight_g\"] = ingredient[\"weight_g\"]\n",
    "\n",
    "for recipe_id in recipeDict:\n",
    "    for ingredient in recipeDict[recipe_id][\"ingredients\"]:\n",
    "        times = int(ingredient['weight_g']/recipeDict[recipe_id][\"min_ingredient_weight_g\"])\n",
    "        recipeDict[recipe_id][\"ingredients_g_normalised\"].append({\n",
    "            \"ingredient\" : ingredient[\"ingredient\"],\n",
    "            \"weight\": recipeDict[recipe_id][\"ingredients_g\"][ingredient[\"ingredient\"].strip()] / recipeDict[recipe_id][\"total_ingredient_weight_g\"] * 10\n",
    "        })\n",
    "        # this is used for popularity search\n",
    "        recipeDict[recipe_id][\"ingredients_popularity\"][ingredient['ingredient'].replace(' ','_')] = times\n",
    "        if len(ingredient['ingredient'].split()) > 0:\n",
    "            words = ingredient['ingredient'].split()\n",
    "            for i in words:\n",
    "                if i not in recipeDict[recipe_id][\"ingredients_popularity\"]:\n",
    "                    recipeDict[recipe_id][\"ingredients_popularity\"][i] = 0\n",
    "                recipeDict[recipe_id][\"ingredients_popularity\"][i] += times\n",
    "        \n",
    "        # this is used for text search\n",
    "        for i in range(times):\n",
    "            recipeDict[recipe_id][\"ingredients_weight_g\"].append(ingredient[\"ingredient\"])\n",
    "\n",
    "    # normalize popularity\n",
    "    mKey = max(recipeDict[recipe_id][\"ingredients_popularity\"],key=recipeDict[recipe_id][\"ingredients_popularity\"].get)\n",
    "    m = recipeDict[recipe_id][\"ingredients_popularity\"][mKey]\n",
    "    for k in recipeDict[recipe_id][\"ingredients_popularity\"]:\n",
    "        recipeDict[recipe_id][\"ingredients_popularity\"][k] = recipeDict[recipe_id][\"ingredients_popularity\"][k]/m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### push preprocessed data to es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushing 2256 documents\n",
      "(2256, [])\n",
      "pushed to elasticsearch\n"
     ]
    }
   ],
   "source": [
    "#push recipe detail to elasticsearch\n",
    "recipes = []\n",
    "for key in recipeDict:\n",
    "    r = recipeDict[key].copy()\n",
    "    del r[\"ingredients\"]\n",
    "    recipes.append(r)\n",
    "\n",
    "err = eshelper.bulkIndex(recipes,\"recipe_detail\",\"{recipe_id}\")\n",
    "if err != None:\n",
    "    print(err.errors)\n",
    "else:\n",
    "    print(\"pushed to elasticsearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test search recipe detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 10 Hits:\n"
     ]
    }
   ],
   "source": [
    "#search documents\n",
    "eshelper.searchByIngredient(\"recipe_detail*\", \"cheese\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read and push nutritions and unit data to es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushing 553 documents\n",
      "None\n",
      "pushing 64 documents\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# process ingredients and units to es\n",
    "with open('../data/unit_to_gram_convertion.json', 'r') as f:\n",
    "    UNITS_DICT = json.load(f)\n",
    "with open('../data/nutritions_dict.json', 'r') as f:\n",
    "    NUTRITIONS_DICT = json.load(f)\n",
    "\n",
    "\n",
    "NUTRITIONS = []\n",
    "UNITS = []\n",
    "\n",
    "for key in NUTRITIONS_DICT:\n",
    "    d = NUTRITIONS_DICT[key]\n",
    "    d[\"ingredient\"] = key\n",
    "    NUTRITIONS.append(d)\n",
    "\n",
    "for key in UNITS_DICT:\n",
    "    v = UNITS_DICT[key]\n",
    "    UNITS.append({\n",
    "        \"unit\": key,\n",
    "        \"value\": v\n",
    "    })\n",
    "\n",
    "\n",
    "err = eshelper.bulkIndex(NUTRITIONS,\"ingredients\",\"{ingredient}-{id}\")\n",
    "print(err)\n",
    "\n",
    "err = eshelper.bulkIndex(UNITS,\"units\",\"{unit}\")\n",
    "print(err)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ae1cb62954322ad839fd1fbe8e5ac37e8094a7fa494490d25755b965da49e0f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py3.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
